{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import geojson\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from shapely.geometry import (\n",
    "    LineString, mapping, shape\n",
    ")\n",
    "from shapely.ops import (\n",
    "    split as shapely_split, transform\n",
    ")\n",
    "\n",
    "from python_gis.poc.landgrid_processor import LandgridProcessor\n",
    "from python_gis.poc.io.pgsql import PgWriter\n",
    "from python_gis.poc.io.mssql import MsWriter\n",
    "from python_gis.poc.io.shapefile import (\n",
    "    read_shapefile\n",
    ")\n",
    "from python_gis.poc.tools.spatial import (\n",
    "    remove_holes, fix_anti_meridian\n",
    ")\n",
    "import python_gis.poc.util.log_config\n",
    "from python_gis.poc.util.sql_config import (\n",
    "    TX_BLOCKS, US_COUNTIES\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $DIML_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ms Sql\n",
    "ms_driver = os.environ[\"MSSQL_DRIVER\"]\n",
    "ms_host = os.environ[\"MSSQL_SERVER\"]\n",
    "ms_db = os.environ[\"MSSQL_DATABASE\"]\n",
    "ms_user = os.environ[\"MSSQL_UID\"]\n",
    "ms_pwd = os.environ[\"MSSQL_PWD\"]\n",
    "\n",
    "# Postgis\n",
    "pg_host = os.environ[\"PG_SERVER\"]\n",
    "pg_db = os.environ[\"PG_DATABASE\"]\n",
    "pg_user = os.environ[\"PG_UID\"]\n",
    "pg_pwd = os.environ[\"PG_PWD\"]\n",
    "\n",
    "# WGS84 (epsg:4326)\n",
    "gdb_path = os.path.join(os.environ[\"DATA_DIR\"], 'landgrid', 'DI_basemaps_WGS84.gdb')\n",
    "ddl_path = os.path.join(os.environ[\"DIML_HOME\"], 'database', 'mssql', 'schema.sql')\n",
    "out_path = os.path.join(os.environ[\"DATA_DIR\"], 'shapefile_out')\n",
    "idx_path = os.path.join(os.environ[\"DIML_HOME\"], 'database', \"indexes.sql\")\n",
    "test_path = os.path.join(os.environ[\"DATA_DIR\"], 'mssql_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissolve Abstracts to Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tx_path = os.path.join(out_path, f'Texas_Abstracts.shp')\n",
    "tx_df = gpd.read_file(tx_path)\n",
    "\n",
    "# TODO: May need to exclude NULL Township as it results in large\n",
    "#  MultiPolygons. Check against reference (TWP: NULL, BLK: 1).\n",
    "tx_df.dropna(how='all', subset=['Township', 'Block'],\n",
    "             inplace=True)\n",
    "\n",
    "tx_df.loc[tx_df.Township.isna(), ['Township']] = 'Missing'\n",
    "tx_df.loc[tx_df.Block.isna(), ['Block']] = 'Missing'\n",
    "\n",
    "tx_blocks_df = (tx_df.loc[:, ['Township', 'Block', 'geometry']]  # .copy()\n",
    "                .dissolve(by=['Township', 'Block'], aggfunc='first')\n",
    "                .reset_index()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_blocks_df.loc[(tx_blocks_df.Township == 'Missing') & \n",
    "                 (tx_blocks_df.Block == '1'), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deaggregate MultiPolygons to Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multipolygons\n",
    "tx_blocks_mp_df = (tx_blocks_df.loc[tx_blocks_df.geometry.geom_type == 'MultiPolygon', :]\n",
    "                   .copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split list of geometries into DataFrame columns\n",
    "df_polys = pd.DataFrame(tx_blocks_mp_df.geometry.tolist()\n",
    "                        , index=tx_blocks_mp_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save original index values\n",
    "df_polys['id'] = df_polys.index\n",
    "\n",
    "# Melt (convert columns to rows)\n",
    "df_polys = df_polys.melt(\n",
    "            id_vars='id'\n",
    "            , value_name='SinglePolygon'\n",
    "        )  #.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove empty values\n",
    "df_polys.dropna(subset=['SinglePolygon'], inplace=True)\n",
    "df_polys.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with original dissolved data set\n",
    "df_deagg = tx_blocks_df.join(df_polys, how='left').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deagg.loc[df_deagg.geometry.geom_type == 'MultiPolygon', ['geometry']] = \\\n",
    "    df_deagg[df_deagg.geometry.geom_type == 'MultiPolygon'].SinglePolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_deagg.drop(columns=['variable', 'SinglePolygon'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deagg.loc[(tx_blocks_df.Township == 'Missing') &\n",
    "             (tx_blocks_df.Block == '1'), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "county_path = os.path.join(out_path, f'{US_COUNTIES}_shgrid.shp')\n",
    "county_df = gpd.read_file(county_path)\n",
    "county_df.sindex\n",
    "\n",
    "county_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just slice Block 1\n",
    "- All of these 580 records have the same index value because they were originally a single record, but now they will be re-indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olap_df = df_deagg.loc[(df_deagg.Township == 'Missing') & \n",
    "                       (df_deagg.Block == '1'), :].copy()\n",
    "\n",
    "# Each polygon is unique so reset index can be done here.\n",
    "olap_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial join with Counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "olaps_df = gpd.sjoin(olap_df, county_df, how='inner', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note same index value\n",
    "olaps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate County Names for the same record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olaps_pre_df = (olaps_df.loc[:, ['County_Nam']]\n",
    "                    .reset_index()\n",
    "                    .drop_duplicates()  # remove duplicate names\n",
    "                    .set_index('index')\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olaps_pre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the equivalent of STRING_AGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olaps_join_df = (olaps_pre_df\n",
    "                     .groupby(olaps_pre_df.index, sort=False)\n",
    "                     .aggregate(**{'Colaps': ('County_Nam', ','.join)})  # Pandas 0.25\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olaps_join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tx_block_path = os.path.join(test_path, f'{TX_BLOCKS}_deagg.shp')\n",
    "df_deagg.to_file(tx_block_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
